## Big Mart Sales Prediction â€“ Stacking Ensemble
### ðŸ“Œ Overview
This repository contains a complete machine learning pipeline for predicting Item Outlet Sales for the Big Mart Sales Prediction challenge.
The solution combines thorough data cleaning, advanced feature engineering, and a 5â€‘fold Outâ€‘ofâ€‘Fold stacking ensemble with XGBoost, LightGBM, and CatBoost base learners blended by a Ridge regression metaâ€‘model.
The script produces a readyâ€‘toâ€‘submit submission.csv.

### ðŸš€ Features
Handles missing values, categorical cleanup, and numeric type coercion.

Advanced feature engineering:

Price_per_Weight, MRP_log, Visibility_log, MRP_by_Age

Outlet age

Target encoding for items, outlets, and combined item type.

Uses OneHotEncoder with sparse_output=True for sklearn â‰¥1.2 compatibility.

Converts sparse matrices to dense arrays when required by models.

5â€‘fold OOF stacking to train metaâ€‘model without overfitting.

Efficient fixed hyperparameters (no long tuning) for fast training.

Outputs submission file in minutes.

### ðŸ“œ Approach
Data preprocessing â€“ fix missing values, unify categorical labels, convert data types.

Feature engineering â€“ create meaningful numerical and categorical features.

Model training â€“ XGBoost, LightGBM, CatBoost trained in 5â€‘fold OOF fashion.

Stacking â€“ Ridge regression on OOF outputs.

Prediction & submission â€“ blend predictions across folds to produce final CSV.
